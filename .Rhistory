chicago <- readRDS("./data/chicago.rds")
str(chicago)
chicago <- rename(chicago, pm25 = pm25tmean2, dewpoint = dptp)
head(chicago)
chicago <- rename(chicago, pm25 = pm25tmean2, dewpoint = dptp)
head(chicago)
library(dplyr)
chicago <- readRDS("./data/chicago.rds")
str(chicago)
names(chicago)
head(select(chicago, city:date))
head(select(chicago, -(city:date)))
i <- match("city", names(chicago))
j <- match("date", names(chicago))
head(chicago[, -(i:j)])
chic.f <- filter(chicago, pm25tmean2 > 30)
head(chic.f)
chic.f <- filter(chicago, pm25tmean2 > 30 & tmpd > 80)
head(chic.f, 10)
chicago <- arrange(chicago, date)
head(chicago, 3)
tail(chicago, 3)
chicago <- arrange(chicago, desc(date))
head(chicago, 3)
tail(chicago, 3)
chicago <- rename(chicago, pm25 = pm25tmean2, dewpoint = dptp)
head(chicago)
chicago <- rename(chicago, pm25 = pm25tmean2, dewpoint = dptp)
head(chicago)
library(dplyr)
chicago <- readRDS("./data/chicago.rds")
str(chicago)
names(chicago)
head(select(chicago, city:date))
library(dplyr)
chicago <- readRDS("./data/chicago.rds")
str(chicago)
names(chicago)
head(select(chicago, city:date))
View(chicago)
library(dplyr)
chicago <- readRDS("./data/chicago.rds")
str(chicago)
library(dplyr)
chicago <- readRDS("./data/chicago.rds")
str(chicago)
library(dplyr)
chicago <- readRDS("./data/chicago.rds")
str(chicago)
rm(list = ls())
library(dplyr)
chicago <- readRDS("./data/chicago.rds")
str(chicago)
names(chicago)
head(select(chicago, city:date))
head(select(chicago, -(city:date)))
i <- match("city", names(chicago))
j <- match("date", names(chicago))
head(chicago[, -(i:j)])
chic.f <- filter(chicago, pm25tmean2 > 30)
head(chic.f)
chic.f <- filter(chicago, pm25tmean2 > 30 & tmpd > 80)
head(chic.f, 10)
chic.f <- filter(chicago, pm25tmean2 > 30 & tmpd > 80)
head(chic.f, 10)
rm(list = ls())
library(dplyr)
chicago <- readRDS("./data/chicago.rds")
str(chicago)
str(chicago)
chicago <- mutate(chicago, pm25detrend = pm25 - mean(pm25, na.rm = TRUE))
chicago <- mutate(chicago, pm25detrend = pm25-mean(pm25, na.rm = TRUE))
chicago <- rename(chicago, pm25 = pm25tmean2, dewpoint = dptp)
head(chicago)
chicago <- mutate(chicago, pm25detrend = pm25-mean(pm25, na.rm = TRUE))
head(select(chicago, pm25, pm25detrend))
UScomms_df <- read.csv("./data/getdata_data_ss06hid.csv")
setwd("C:/Users/alexa/OneDrive/Desktop/DS_Specialisation/03_Getting_And_Cleaning_Data/code")
UScomms_df <- read.csv("./data/getdata_data_ss06hid.csv")
UScomms_df
library(dplyr)
UScomms_df
str(UScomms_df)
unique(UScomms_df[c("ST")])
UScomms_df_filtered <- filter(UScomms_df, ACR = 3, AGS = 6)
UScomms_df_filtered <- filter(UScomms_df, ACR == 3, AGS == 6)
head(UScomms_df_filtered)
agriculturalLogical <- UScomms_df$ACR == 3 & UScomms_df$AGS == 6
agriculturlalLogical
agriculturalLogical
which(UScomms_df == agriculturalLogical)
which(agriculturalLogical == TRUE)
UScomms_df_select <- select(UScomms_df, ACR, AGS)
UScomms_df_mutate <- mutate(UScomms_df, row_num == row_number)
length(UScomms_df)
?row_number
row_index <- 1:6496
UScomms_df_mutate <- mutate(UScomms_df, row_num == row_index)
UScomms_df_mutate <- mutate(UScomms_df, row_num = row_index)
UScomms_df_mutate
UScomms_df_mutate <- mutate(UScomms_df_select, row_num = row_index)
UScomms_df_mutate
UScomms_df <- (read.csv("./data/getdata_data_ss06hid.csv")) %>%
select(ACR, AGS) %>%
mutate(row_num = 1:6496) %>%
filter(ACR == 3, AGS == 6) %>%
head
UScomms_df
UScomms_df <- (read.csv("./data/getdata_data_ss06hid.csv")) %>%
select(ACR, AGS) %>%
mutate(row_num = 1:6496) %>%
filter(ACR == 3, AGS == 6) %>%
print()
UScomms_df <- (read.csv("./data/getdata_data_ss06hid.csv")) %>%
select(ACR, AGS) %>%
mutate(row_num = 1:6496) %>%
filter(ACR == 3, AGS == 6) %>%
head()
UScomms_df <- (read.csv("./data/getdata_data_ss06hid.csv")) %>%
select(ACR, AGS) %>%
mutate(row_num = 1:6496) %>%
filter(ACR == 3, AGS == 6)
head(UScomms_df, 3)
# Clear environment
rm(list = ls())
# Clear packages
p_unload(all)  # Remove all add-ons
# Clear console
cat("\014")  # ctrl+L
library(dplyr)  ## library for selecting and sorting
GDP_df <- read.csv("./data/getdata_data_GDP.csv", stringsAsFactors=FALSE)  ## read in the GDP dataframe
setwd("C:/Users/alexa/OneDrive/Desktop/DS_Specialisation/03_Getting_And_Cleaning_Data/code")
GDP_df <- read.csv("./data/getdata_data_GDP.csv", stringsAsFactors=FALSE)  ## read in the GDP dataframe
GDP_df$X.3 <- gsub(",", "", GDP_df$X.3) ## remove commas in the GDP column to facilitate character conversion
EDU_df <- read.csv("./data/getdata_data_EDSTATS_Country.csv", stringsAsFactors=FALSE)  ## read in the education dataframe
colnames(GDP_df)[1] <- "CountryCode"  ## change column name so common columns have same name to allow merging
GDP_vec <- GDP_df$CountryCode  ## create a vector from the CountryCode column in GDP dataframe
GDP_vec_clean <- GDP_vec[GDP_vec != ""]  ## remove the "" values in the vector
EDU_vec <- EDU_df$CountryCode  ## create a vector from the CountryCode column in education dataframe
matches <- match(GDP_vec_clean, EDU_vec)  ## create a vector of all of the matches between the two vectors
matches_clean <- matches[!is.na(matches)]
length(matches_clean)  ## the length of the vector equals the number of matches
countries_GDP <- merge(x = GDP_df, y = EDU_df, by = "CountryCode", all = TRUE)
countries <- countries_GDP$CountryCode
countries_clean <- countries[countries != ""]
countries_unique <- unique(countries_clean)
matches
View(EDU_df)
match_countries <- merge(x = GDP_df, y = EDU_df, by = "CountryCode", all = FALSE)
countries <- match_countries$CountryCode
x <- C(2, 6, 8)
x = c(2, 6, 8)
y = c(6, 8, 9)
match(x, y)
View(GDP_df)
GDP_df <- read.csv("./data/getdata_data_GDP.csv", stringsAsFactors=FALSE)  ## read in the GDP dataframe
match_countries_sorted <- arrange(match_countries, )
GDP_df$X.3 <- gsub(",", "", GDP_df$X.3) ## remove commas in the GDP column to facilitate character conversion
GDP_df <- read.csv("./data/getdata_data_GDP.csv", stringsAsFactors=FALSE)  ## read in the GDP dataframe
EDU_df <- read.csv("./data/getdata_data_EDSTATS_Country.csv", stringsAsFactors=FALSE)  ## read in the education dataframe
colnames(GDP_df)[1] <- "CountryCode"  ## change column name so common columns have same name to allow merging
colnames(GDP_df)[2] <- "Ranking" ## change column Gross.domestic.product.2012 name to something more manageable
countries_GDP <- merge(x = GDP_df, y = EDU_df, by = "CountryCode", all = FALSE) %>%  ## merge the dataframes
select(Ranking, CountryCode, Short.Name) %>%  ## select only the GDP ranking, country code and short name columns
transform(Ranking = as.numeric(Ranking)) %>%  ## the GDP Ranking column is in character format -> transform to numeric
arrange(Ranking)  ## sort by GDP ascending (by default)
head(countries_GDP, 13)  ### print first thirteen rows and read the country at row 13
countries_GDP <- merge(x = GDP_df, y = EDU_df, by = "CountryCode", all = FALSE) %>%  ## merge the dataframes
select(Ranking, CountryCode, Short.Name) %>%  ## select only the GDP ranking, country code and short name columns
transform(Ranking = as.numeric(Ranking)) %>%  ## the GDP Ranking column is in character format -> transform to numeric
arrange(desc(Ranking))  ## sort by GDP ascending (by default)
head(countries_GDP, 13)  ### print first thirteen rows and read the country at row 13
UScomms_df <- (read.csv("./data/getdata_data_ss06hid.csv"))
agriculturalLogical <- UScomms_df$ACR == 3 & UScomms_df$AGS == 6
which(agriculturalLogical == TRUE)
UScomms_df <- (read.csv("./data/getdata_data_ss06hid.csv")) %>%  ## read the US Communities dataframe
select(ACR, AGS) %>%  ## select only the lot size and sales of agricultural products columns
mutate(row_num = 1:6496) %>%  ## add a column to act as row numbers
filter(ACR == 3, AGS == 6)  ## filter the column according to the parameters defined above
head(UScomms_df, 3)  ## print the first three results -> the row_num values give the requested result
jeff <- readJPEG("./data/getdata_jeff.jpg", native = TRUE)  ## read the JPEG file with the parameter native = TRUE
setwd("C:/Users/alexa/OneDrive/Desktop/DS_Specialisation/03_Getting_And_Cleaning_Data/code")
jeff <- readJPEG("./data/getdata_jeff.jpg", native = TRUE)  ## read the JPEG file with the parameter native = TRUE
install.packages("jpeg")
library(jpeg)
jeff <- readJPEG("./data/getdata_jeff.jpg", native = TRUE)  ## read the JPEG file with the parameter native = TRUE
quantile(jeff, probs = 0.3)  ## calculate the 30th percentile
quantile(jeff, probs = 0.8)  ## calculate the 80th percentile
GDP_df <- read.csv("./data/getdata_data_GDP.csv", stringsAsFactors=FALSE)  ## read in the GDP dataframe
EDU_df <- read.csv("./data/getdata_data_EDSTATS_Country.csv", stringsAsFactors=FALSE)  ## read in the education dataframe
colnames(GDP_df)[1] <- "CountryCode"  ## change column name so common columns have same name to allow merging
colnames(GDP_df)[2] <- "Ranking" ## change the column name "Gross.domestic.product.2012" to something more manageable
average_ranking <- merge(x = GDP_df, y = EDU_df, by = "CountryCode", all = TRUE) %>%  ## merge the dataframes
select(Income.Group, Ranking) %>%  ## select only the coutry code, Income.Group and GDP ranking columns
transform(Ranking = as.numeric(Ranking)) %>%  ## the GDP ranking column is in character format -> transform to numeric
group_by(Income.Group) %>%  ## group the dataframe by Income.Group
filter(!is.na(Income.Group), !is.na(Ranking)) %>%  ## filter out the NA values
summarise(mean = sprintf(mean(Ranking), fmt = '%#.6f')) %>%  ## calculate the mean GDP ranking for the grouped countries
print  ## print the result
GDP_df <- read.csv("./data/getdata_data_GDP.csv", stringsAsFactors=FALSE)  ## read in the GDP dataframe
EDU_df <- read.csv("./data/getdata_data_EDSTATS_Country.csv", stringsAsFactors=FALSE)  ## read in the education dataframe
colnames(GDP_df)[1] <- "CountryCode"  ## change column name so common columns have same name to allow merging
colnames(GDP_df)[2] <- "Ranking" ## change the column name "Gross.domestic.product.2012" to something more manageable
ranking_df <- merge(x = GDP_df, y = EDU_df, by = "CountryCode", all = TRUE) %>%  ## merge the dataframes
select(Short.Name, Ranking, Income.Group) %>%  ## select only the coutry code, Income.Group and GDP ranking columns
transform(Ranking = as.numeric(Ranking)) %>%  ## the GDP ranking column is in character format -> transform to numeric
filter(Ranking <=38, Income.Group == "Lower middle income") %>%  ## filter out the NA values
print  ## print the result
dim(countries_GDP)
countries_GDP
# Clear environment
rm(list = ls())
# Clear packages
p_unload(all)  # Remove all add-ons
# Clear console
cat("\014")  # ctrl+L
col_names <- c("address", "direction", "street", "crossStreet", "intersection", "Location.1")
tolower(col_names)
split_names <- strsplit(col_names)
split_names <- strsplit(col_names, "\\.")
split_names
my_list <- list(letters = c("A", "b", "c"), numbers = 1:3, matrix(1:25, ncol = 5))
head(my_list)
my_list[1]
my_list$letters
my_list[[1]]
first_element <- function(x){x[1]}
sapply(split_names, first_element)
setwd("C:/Users/alexa/OneDrive/Desktop/DS_Specialisation/03_Getting_And_Cleaning_Data/code")
reviews <- read.csv("./data/reviews.csv")
solutions <- read.csv("./data/solutions.csv")
head(reviews, 2)
head(solutions)
head(solutions, 2)
names(reviews)
sub("_", "", names(reviews), )
head(solutions, 2)
names(reviews)
sub("_", "", names(reviews), )
test_name <- "this_is_a_test"
sub("_", "", test_name)
gsub("_", "", test_name)
nchar("Alexander Cormack")
nchar("Alexander Cormack", 1, 9)
substr("Alexander Cormack", 1, 9)
paste("Alexander", "Cormack")
paste("Alexander", "Cormack", sep = "$")
paste0("Alexander", "Cormack")
library(stringr)
str_trim("     Alexander        ")
library(knitr)
setwd("C:/Users/alexa/OneDrive/Desktop/DS_Specialisation/03_Getting_And_Cleaning_Data/code")
d1 = date()
d1
class(d1)
d2
d2 = Sys.Date()
d2
class(d2)
format(d2, "%a %d %b")
format(d2, "%a %d %b")
format(d2, "%a %d %b")
d2 = Sys.Date()
d2
d2 = Sys.Date()
d2
d2 = Sys.Date()
d2
format(d2, "%a %d %b")
format(d2, "%a %d %b")
x = c("1jan1960", "2jan1960", "31mar1960", "30jul1960")
z = as.Date(x, "%d%b%Y")
x = c("1jan1960", "2jan1960", "31mar1960", "30jul1960")
z = as.Date(x, "%d%b%Y")
z
x = c("1ene1960", "2jan1960", "31mar1960", "30jul1960")
z = as.Date(x, "%d%b%Y")
z
x = c("1ene1960", "2jan1960", "31mar1960", "30jul1960")
z = as.Date(x, "%d%b%Y")
z
x = c("1jan1960", "2jan1960", "31mar1960", "30jul1960"); z = as.Date(x, "%d%b%Y")
z
x <- c("1jan1960", "2jan1960", "31mar1960", "30jul1960")
z <- as.Date(x, "%d%b%Y")
z
d1 <- date()
d1
d2 <- Sys.Date()
d2
x <- c("01/01/1960", "02/01/1960", "31/03/1960", "30/07/1960")
z <- as.Date(x, "%d/%m/%Y")
z
x <- c("01/01/1960", "02/01/1960", "31/03/1960", "30/07/1960")
z <- as.Date(x, format = "%d/%m/%Y")
z
format(d2, "%d/%m/%Y")
x <- c("01/01/1960", "02/01/1960", "31/03/1960", "30/07/1960")
z <- as.Date(x, format = "%d/%m/%Y")
z
?as.Date
z[1] - z[2]
as.numeric(z[1] - z[2])
weekdays(d2)
months(d2)
julian(d2)
install.packages("lubridate")
library(lubridate)
ymd("20221016")
mdy(09112001)
dmy(16102022)
ymd_hms("2022-10-16 14:27:45")
ymd_hms("2022-10-16 14:27:45", tz = "Pacific/Auckland")
?Sys.timezone
x <- dmy(c("1jan2013", "2jan2013", "31mar2013", "30jul2013"))
wday(x[1])
wday(x{1}, label=TRUE)
wday(x[1], label=TRUE)
rm(list = ls())
setwd("C:/Users/alexa/OneDrive/Desktop/DS_Specialisation/03_Getting_And_Cleaning_Data/code")
library(swirl)
swirl()
Sys.getlocale("LC_TIME")
Sys.setlocale("LC_TIME", "en_US.UTF-8")
detach("package:lubridate", unload = TRUE)
swirl()
library(lubridate)
help(package = "lubridate")
help(package = lubridate)
this_day <- today()
this_day
year(this_day)
wday(this_day)
wday(this_day, label=TRUE)
this_moment <- now()
this_moment
hour(this_moment)
my_date <- ymd("1989-05-17")
my_date
class(my_date)
ymd("1989 May 17")
mdy("maarch 12, 1975")
mdy("march 12, 1975")
mdy("March 12, 1975")
dmy(25081985)
ymd("192012")
ymd("1920/1/2")
dt1
dt1_parsed <- ymd_hms(dt1)
dt1_parsed
class(dt1_parsed)
hms("03:22:14")
dt2
ymd(dt2)
update(this_moment, hours = 8, minutes = 34, seconds = 55)
this_moment
this_moment <- update(this_moment, hours = 15, minutes = 53)
this_moment
?now()
nyc <- now(tzone = "America/New_York")
nyc
depart <- nyc + days(2)
depart
depart <- update(depart, hours = 17, minutes = 34)
depart
arrive <- depart + hours(15) + minutes(50)
?with_tz
arrive <- with_tz(arrive, tzone = "Asia/Hong_Kong")
arrive
last_time <- mdy("June 17, 2008", tz = "Singapore")
last_time
?interval()
?interval
how_long <- interval(last_time/arrive)
how_long <- interval(last_time, arrive)
as.period(how_long)
stopwatch()
UScomms_df <- (read.csv("./data/getdata_data_ss06hid.csv"))
View(UScomms_df)
col_names <- colnames(UScomms_df)
col_names
split_names <- strsplit(col_names, "wgtp")
split_names
split_names[123]
?strsplit
strsplit(names(UScomms_df), "wgtp")
GDP_df <- read.csv("./data/getdata_data_GDP.csv", stringsAsFactors=FALSE)  ## read in the GDP dataframe
View(GDP_df)
library(dplyr)
GDP_raw <- GDP_df$X.3
GDP_raw
sapply(GDP_raw, gsub(",", ""))
sapply(GDP_raw, gsub(",", "", GDP_raw))
gsub(",", "", GDP_raw)
GDP_raw <- gsub(",", "", GDP_df$X.3) ## create a character vector of the GDP column and remove the commas
transform(GDP_raw = as.numeric(GDP_raw))
GDP_numeric <- as.numeric(GDP_raw)
GDP_numeric
result <- mean(GDP_numeric)
result
GDP_clean <- !is.na(GDP_numeric)
GDP_clean
GDP_clean <- is.na(GDP_numeric)
GDP_na <- is.na(GDP_numeric)
GDP_no_na <- GDP_numeric[!GDP_na]
GDP_no_na
mean(GDP_no_na)
GDP_numeric <- as.numeric(GDP_raw[5:134])  ## transform the character vector into a numeric vector only of the country rows (i.e., rows 5 to 134)
GDP_na <- is.na(GDP_numeric)  ## create a logical vector of the NA values
GDP_no_na <- GDP_numeric[!GDP_na]  ## filter out the NA values
mean(GDP_no_na)  ## find the mean (i.e., )
GDP_numeric <- as.numeric(GDP_raw[5:194])  ## transform the character vector into a numeric vector only of the ranked country rows (i.e., rows 5 to 194)
GDP_na <- is.na(GDP_numeric)  ## create a logical vector of the NA values
GDP_no_na <- GDP_numeric[!GDP_na]  ## filter out the NA values
mean(GDP_no_na)  ## find the mean (i.e., )
grep("^United", GDP_df$X.2)
library(dplyr)  ## library for selecting and sorting
GDP_df <- read.csv("./data/getdata_data_GDP.csv", stringsAsFactors=FALSE)  ## read in the GDP dataframe
EDU_df <- read.csv("./data/getdata_data_EDSTATS_Country.csv", stringsAsFactors=FALSE)  ## read in the education dataframe
colnames(GDP_df)[1] <- "CountryCode"  ## change column name so common columns have same name to allow merging
colnames(GDP_df)[2] <- "Ranking" ## change column Gross.domestic.product.2012 name to something more manageable
countries_GDP <- merge(x = GDP_df, y = EDU_df, by = "CountryCode", all = FALSE) %>%  ## merge the dataframes
select(Ranking, CountryCode, Short.Name) %>%  ## select only the GDP ranking, country code and short name columns
transform(Ranking = as.numeric(Ranking)) %>%  ## the GDP Ranking column is in character format -> transform to numeric
arrange(desc(Ranking))  ## sort by GDP ascending (by default)
dim(countries_GDP)  ## number of rows in the dataframe should be equal to the number of matches (i.e. the union of the two CountryCode columns)
head(countries_GDP, 13)  ### print first thirteen rows: St. Kitts is at row 13
View(EDU_df)
str(EDU_df)
library(dplyr)  ## library for selecting and sorting
merge_df <- merge(x = GDP_df, y = EDU_df, by = "CountryCode", all = TRUE) %>%  ## merge the dataframes
# Question 5 #################################################
# Cut the GDP ranking into 5 separate quantile groups. Make a table versus Income.Group. How many countries
# are Lower middle income but among the 38 nations with highest GDP?
# 5
# 0
# 13
# 12
library(dplyr)  ## library for selecting and sorting
countries_GDP <- merge(x = GDP_df, y = EDU_df, by = "CountryCode", all = FALSE) ## merge the dataframes
View(countries_GDP)
?merge
notes <- countries_GDP$Special.Notes
notes
grep("Fiscal year end: June 30", countries_GDP$Special.Notes)
library(dplyr)  ## library for selecting and sorting
GDP_df <- read.csv("./data/getdata_data_GDP.csv", stringsAsFactors=FALSE)  ## read in the GDP dataframe
EDU_df <- read.csv("./data/getdata_data_EDSTATS_Country.csv", stringsAsFactors=FALSE)  ## read in the education dataframe
colnames(GDP_df)[1] <- "CountryCode"  ## change column name so common columns have same name to allow merging
countries_GDP <- merge(x = GDP_df, y = EDU_df, by = "CountryCode", all = FALSE) ## merge the dataframes
fiscal_june_30 <- grep("Fiscal year end: June 30", countries_GDP$Special.Notes)  ## search the Special.Notes column for the required text string
length(fiscal_june_30)  ## retunr the number of elements found (i.e., 13)
grep("^United", GDP_df$X.2)  ## the countryNames column is actually X.2 - three values are returned: 1 (US), 5 (UK), 36 (UAE)
GDP_df <- read.csv("./data/getdata_data_GDP.csv", stringsAsFactors=FALSE)  ## read in the GDP dataframe
GDP_raw <- gsub(",", "", GDP_df$X.3) ## create a character vector of the GDP column and remove the commas
GDP_numeric <- as.numeric(GDP_raw[5:194])  ## transform the character vector into a numeric vector only for the ranked country rows (i.e., rows 5 to 194)
GDP_na <- is.na(GDP_numeric)  ## create a logical vector of the NA values
GDP_no_na <- GDP_numeric[!GDP_na]  ## filter out the NA values
mean(GDP_no_na)  ## find the mean (i.e., 377652.4)
UScomms_df <- (read.csv("./data/getdata_data_ss06hid.csv"))  ## read the CSV file
split_names <- strsplit(names(UScomms_df), "wgtp")  ## split the column names of the dataframe on the characters "wgtp"
split_names[123]  ## display the 123rd element (i.e., "" "15")
library(quantmod)
install.packages("quantomod")
install.packages("quantmod")
library(quantmod)
amzn = getSymbols("AMZN",auto.assign=FALSE)
sampleTimes = index(amzn)
str(sampleTimes)
twenty_twelve <- grep("^2012", sampleTimes)
head(twenty_twelve)
length(twenty_twelve)
tail(twenty_twelve)
twenty_twelve_dates <- sampleTimes[1261:1510]
twenty_twelve_dates
First_last <- c(twenty_twelve[1], twenty_twelve[-1])
First_last
twenty_twelve[1]
twenty_twelve[-1]
first_last <- c(twenty_twelve[1], twenty_twelve[length(twenty_twelve)])
first_last
twenty_twelve_dates <- sampleTimes[twenty_twelve[1]:twenty_twelve[length(twenty_twelve)]]
twenty_twelve_dates
first <- twenty_twelve[1]
last <- twenty_twelve[length(twenty_twelve)]
twenty_twelve_dates <- sampleTimes[first:last)]]
twenty_twelve_dates <- sampleTimes[first:last]
twenty_twelve_dates
mondays <- c()  ## create an empty numeric vector to store the instances of Mondays
for (i in seq_along(twenty_twelve_dates)) { ## loop through all the dates
## check if the number of complete cases is above the threshold
if(wday(twenty_twelve_dates[i]) == 2) {
## add the correlation coefficient of sulfate and nitrate to the numeric vector
mondays <- c(mondays, twenty_twelve_dates[1])
}
}
## return the numeric vector of correlation coefficients of all the stations above the threshold
length(mondays)
str(sampleTimes) ## check the structure of the vector (i.e. )
str(sampleTimes) ## check the structure of the vector (i.e. it is a list of 3975 dates)
twenty_twelve <- grep("^2012", sampleTimes)  ## search the dates from the sampleTimes that begin with 2012 (N.B. the resulting vector contains the indices)
length(twenty_twelve)  ## return the number of instances of 2012 (i.e. 250)
first <- twenty_twelve[1]  ## find the first instance of 2012 in sampleTimes
last <- twenty_twelve[length(twenty_twelve)]  ## find the last instance of 2012 in sampleTimes
twenty_twelve_dates <- sampleTimes[first:last]  ## slice sampleTimes to only include the 2012 dates
mondays <- c()  ## create an empty numeric vector to store the instances of Mondays
for (i in seq_along(twenty_twelve_dates)) {
if(wday(twenty_twelve_dates[i]) == 2) {
mondays <- c(mondays, twenty_twelve_dates[1])
}
}
length(mondays)  ## return the length of the numeric vector (i.e., the number of Mondays -> 47)
