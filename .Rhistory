created = h5createGroup("example.h5", "baa")
created = h5createGroup("example.h5", "foo/foobaa")
h5ls("example.h5")
A = matrix(1:10, nr = 5, nc = 2)
h5write(A, "example.h5", "foo/A")
B = array(seq(0.1, 2.0, by = 0.1), dim = c(5, 2, 2))
attr(B, "scale") <- "liter"
h5write(B, "example.h5", "foo/foobaa/B")
h5ls("example.h5")
df = data.frame(1L:5L, seq(0, 1, length.out = 5),
c("ab", "cde", "fghi", "a", "s"), stringsAsFactors = FALSE)
h5write(df, "example.h5", "df")
h5ls("example.h5")
readA = h5read("example.h5", "foo/A")
readB = h5read("example.h5", "foo/foobaa/B")
readdf = h5read("example.h5", "df")
readA
readB
readdf
h5write(c(12, 13, 14), "example.h5", "foo/A", index = list(1:3, 1))
h5read("example.h5", "foo/A")
h5read("example.h5", "foo/A", index = list(1:3, 1))
rm(list = ls())
GS_connection = url("http://scholar.google.com/citations?user=HI-I60AAAAJhl=en")
htmlCode = readLines(GS_connection)
GS_connection = url("http://scholar.google.com/citations?user=HI-I6C0AAAAJ&hl=en")
htmlCode = readLines(GS_connection)
close(GS_connection)
htmlCode
library(XML)
url <- "http://scholar.google.com/citations?user=HT-I6C0AAAAJ&hl=en"
html <- htmlTreeParse(url, useInternalNodes = T)
library(XML)
url <- "http://scholar.google.com/citations?user=HI-I6C0AAAAJ&hl=en"
html <- htmlTreeParse(url, useInternalNodes = T)
library(XML)
url <- "http://scholar.google.com/citations?user=HI-I6C0AAAAJ&hl=en"
html <- htmlTreeParse(url, useInternalNodes = T)
library(XML)
url <- "http://scholar.google.com/citations?user=HI-I6C0AAAAJ&hl=en"
html <- htmlTreeParse(url, useInternalNodes = TRUE)
install.packages("XML")
install.packages("XML")
GS_connection = url("http://scholar.google.com/citations?user=HI-I6C0AAAAJ&hl=en")
htmlCode = readLines(GS_connection)
close(GS_connection)
htmlCode
library(XML)
url <- "http://scholar.google.com/citations?user=HI-I6C0AAAAJ&hl=en"
html <- htmlTreeParse(url, useInternalNodes = T)
library(XML)
url <- "http://scholar.google.com/citations?user=HI-I6C0AAAAJ&hl=en"
html <- htmlTreeParse(url, useInternalNodes = TRUE)
library(rvest)
library(xml2)
url <- "http://scholar.google.com/citations?user=HI-I6C0AAAAJ&hl=en"
doc <- read_html(url)
doc %>%
html_nodes("a[href^='http://scholar.google.com/citations?user=HI-I6C0AAAAJ&hl=en']") %>%
html_attr("href")
?Sys.chmod
Sys.chmod("./support/TWitter_API.txt", mode = "0400")
Sys.setenv(BEARER_TOKEN = "AAAAAAAAAAAAAAAAAAAAAG4CgQEAAAAAQgl%2FJITBl3UioomXjmpyDp9uz%2Fo%3D6xEkwnQYPYtlSMBMrtB1ot6mr7etopxrkk2rB8rSY2TyKgcUCO")
install.packages("httr")
install.packages("jsonlite")
install.packages("dplyr")
require(httr)
require(jsonlite)
require(dplyr)
bearer_token <- Sys.getenv("$AAAAAAAAAAAAAAAAAAAAAG4CgQEAAAAAQgl%2FJITBl3UioomXjmpyDp9uz%2Fo%3D6xEkwnQYPYtlSMBMrtB1ot6mr7etopxrkk2rB8rSY2TyKgcUCO")
headers <- c(`Authorization` = sprintf('Bearer %s', bearer_token))
params <- list(`user.fields` = 'description',
`expansions` = 'pinned_tweet_id')
handle <- readline('$EU_IPO')
sprintf('https://api.twitter.com/2/users/by?usernames=%s', handle)
handle <- readline('$EU_IPO')
url_handle <-
sprintf('https://api.twitter.com/2/users/by?usernames=%s', handle)
response <-
httr::GET(url = url_handle,
httr::add_headers(.headers = headers),
query = params)
obj <- httr::content(response, as = "text")
print(obj)
handle <- readline('$@EU_IPO')
url_handle <- sprintf('https://api.twitter.com/2/users/by?usernames=%s', handle)
response <-
httr::GET(url = url_handle,
httr::add_headers(.headers = headers),
query = params)
obj <- httr::content(response, as = "text")
print(obj)
handle <- readline('EU_IPO')
url_handle <- sprintf('https://api.twitter.com/2/users/by?usernames=%s', handle)
response <-
httr::GET(url = url_handle,
httr::add_headers(.headers = headers),
query = params)
obj <- httr::content(response, as = "text")
print(obj)
json_data <- fromJSON(obj, flatten = TRUE) %>% as.data.frame
View(json_data)
final <-
sprintf(
"Handle: %s\nBio: %s\nPinned Tweet: %s",
json_data$data.username,
json_data$data.description,
json_data$includes.tweets.text
)
cat(final)
final
str(final)
bearer_token
bearer_token <- Sys.getenv("AAAAAAAAAAAAAAAAAAAAAG4CgQEAAAAAQgl%2FJITBl3UioomXjmpyDp9uz%2Fo%3D6xEkwnQYPYtlSMBMrtB1ot6mr7etopxrkk2rB8rSY2TyKgcUCO")
headers <- c(`Authorization` = sprintf('Bearer %s', bearer_token))
headers
params <- list(`user.fields` = 'description',
`expansions` = 'pinned_tweet_id')
handle <- readline('$USERNAME')
url_handle <-
sprintf('https://api.twitter.com/2/users/by?usernames=%s', handle)
handle <- readline('EU_IPO')
response <-
httr::GET(url = url_handle,
httr::add_headers(.headers = headers),
query = params)
obj <- httr::content(response, as = "text")
print(obj)
handle <- readline('EU_IPO')
url_handle <-   sprintf('https://api.twitter.com/2/users/by?usernames=%s', handle)
url_handle
response <-
httr::GET(url = url_handle,
httr::add_headers(.headers = headers),
query = params)
obj <- httr::content(response, as = "text")
print(obj)
library(rjson)
require(httr)
require(jsonlite)
require(dplyr)
library(purrr)
tweet_id <- "70650192"
url_handle <- glue::glue("https://api.twitter.com/2/tweets/{status_id}/liking_users", status_id = tweet_id)
tweet_id <- "70650192"
url_handle <- glue::glue("https://api.twitter.com/2/users/by?usernames=%s", status_id = tweet_id)
response <-
httr::GET(url = url_handle,
httr::add_headers(.headers = headers),
query = params)
obj <- httr::content(response, as = "text")
print(obj)
response <- httr::GET(url = url_handle,
httr::add_headers(.headers = headers))
# query = params)
obj <- httr::content(response, as = "text")
obj
str(obj)
json_data <- fromJSON(obj, flatten = TRUE) %>% as.data.frame
x <- rjson::fromJSON(obj)
tweet_id <- "70650192"
url_handle <- glue::glue("https://api.twitter.com/2/tweets/{status_id}/liking_users", status_id = tweet_id)
response <- httr::GET(url = url_handle,
httr::add_headers(.headers = headers))
# query = params)
obj <- httr::content(response, as = "text")
x <- rjson::fromJSON(obj)
x$data %>%
purrr::map_chr("username")
tweet_id <- "1394072770661822464"
url_handle <- glue::glue("https://api.twitter.com/2/tweets/{status_id}/liking_users", status_id = tweet_id)
response <- httr::GET(url = url_handle,
httr::add_headers(.headers = headers))
# query = params)
obj <- httr::content(response, as = "text")
x <- rjson::fromJSON(obj)
x$data %>%
purrr::map_chr("username")
install.packages("sqldf")
library(sqldf)
acs <- read.csv("./data/get_data_ss06pid.csv")
setwd("C:/Users/CORMAAL/Desktop/DSEF/DS_Specialisation/03_Getting_And_Cleaning_Data/code")
acs <- read.csv("./data/get_data_ss06pid.csv")
acs <- read.csv("./data/getdata_data_ss06pid.csv")
View(acs)
probWeights1 <- sqldf("select pwgtp1 from acs where AGEP < 50")
View(probWeights1)
probWeights2 <- sqldf("select pwgtp1 and AGEP from acs where AGEP < 50")
View(probWeights2)
probweights3 <- sqldf("select * from acs where AGEP < 50 and pwgtp1")
View(probweights3)
probweights4 <- sqldf("select AGEP, pwgtp1 from acs where AGEP < 50")
View(probweights4)
pw1_less_than_50_years <- sqldf("select pwgtp1 from acs where AGEP < 50")
pw1_and_ages_less_than_50_years <- sqldf("select AGEP, pwgtp1 from acs where AGEP < 50")
x <- unique(acs$AGEP)
y <- sqldf("select distinct AGEP from acs")
z <- sqldf("select AGEP where unique from acs")
rm(list = ls())
cat("\014")  # ctrl+L
library(XML)
library(httr)
url <- "http://biostat.jhsph.edu/~jleek/contact.html"
html2 = GET(url)
content2 = content(html2, as = "text")
parsedHTML = htmlParse(content2, asText = TRUE)
xpathSApply(parsedHTML, "//title", xmlValue)
content2
parsedHTML
parsedHTML[10]
n10 <- '<link rel="stylesheet" href="images/PixelGreen.css" type="text/css">'
x <- nchar(n10)
x
install.packages("foreign")
library(foreign)
?Foreign
data <- read.fortran("./data/getdata_wksst8110.for")
?read.fortran
data <- read.fortran(file = "./data/getdata_wksst8110.for", "14X", "F2.1", "12X")
data <- read.fortran(file = "./data/getdata_wksst8110.for", "3X", "F2.1", "4X")
data <- read.fwf("./data/getdata_wksst8110.for", widths = c(-14, 3, -12))
data
data <- read.fwf("./data/getdata_wksst8110.for", widths = c(-14, 3, -12))
head(data)
data <- read.fwf("./data/getdata_wksst8110.for", widths = c(-27, 4))
head(data, 10)
data <- read.fwf("./data/getdata_wksst8110.for", widths = c(-28, 4))
head(data, 10)
answer <- sum(data[5:])
str(data)
answer <- sum(data[5:, ])
filtered_data <- data[5:, 1]
filtered_data <- data[5:1258, ]
head(filtered_data, 10)
answer <- sum(filtered_data)
str(filtered_data)
numeric_data <- as.numeric(filtered_data)
answer <- sum(numeric_data)
amswer
naswer
answer
parsedHTML
htmlLines <- readLines(url, n=100)
htmlLines[10]
tenth <- nchar(htmlLines[10])
twentieth <- nchar(htmlLines[20])
thirtieth <- nchar(htmlLines[30])
one_hundredth <- nchar(htmlLines[100])
answer5 <- sum(numeric_data)
answer4 <- c(tenth, twentieth, thirtieth, one_hundredth)
answer4
rm(list = ls())
p_unload(all)  # Remove all add-ons
dev.off()  # But only if there IS a plot
cat("\014")  # ctrl+L
data <- read.fwf("./data/getdata_wksst8110.for", widths = c(9, -5, 4, 4, -5, 4, 4, -5, 4, 4, -5, 4, 4))
library(foreign)
data <- read.fwf("./data/getdata_wksst8110.for", widths = c(9, -5, 4, 4, -5, 4, 4, -5, 4, 4, -5, 4, 4))
install.packages("foreign")
setwd("C:/Users/CORMAAL/Desktop/DSEF/DS_Specialisation/03_Getting_And_Cleaning_Data/code")
data <- read.fwf("./data/getdata_wksst8110.for", widths = c(9, -5, 4, 4, -5, 4, 4, -5, 4, 4, -5, 4, 4))
head(data, 10)
data <- read.fwf("./data/getdata_wksst8110.for", widths = c(9, -6, 4, 4, -5, 4, 4, -5, 4, 4, -5, 4, 4))
head(data, 10)
str(data)
data <- read.fwf("./data/getdata_wksst8110.for", widths = c(-1, 9, -5, 4, 4, -5, 4, 4, -5, 4, 4, -5, 4, 4))
head(data, 10)
data_cleaned <- data[-c(1, 2), ]
head(data_cleaned)
colnames(df) <- c("Week", "SST", "SSTA", "SST", "SSTA", "SST", "SSTA", "SST", "SSTA")
colnames(data_cleaned) <- c("Week", "SST", "SSTA", "SST", "SSTA", "SST", "SSTA", "SST", "SSTA")
head(data_cleaned)
data <- read.fwf("./data/getdata_wksst8110.for", widths = c(-1, 9, -5, 4, 4, -5, 4, 4, -5, 4, 4, -5, 4, 4))
colnames(data_cleaned) <- c("Week", "Nino1+2 (SST)", "Nino1+2 (SSTA)", "Nino3 (SST)", "Nino3 (SSTA)",
"Nino34 (SST)", "Nino34 (SSTA)", "Nino4 (SST)", "Nino4 (SSTA)")
data_cleaned <- data[-c(1:4, 2), ]
head(data_cleaned)
colnames(data) <- c("Week", "Nino1+2 (SST)", "Nino1+2 (SSTA)", "Nino3 (SST)", "Nino3 (SSTA)",
"Nino34 (SST)", "Nino34 (SSTA)", "Nino4 (SST)", "Nino4 (SSTA)")
data_cleaned <- data[-c(1:4, 2), ]
head(data_cleaned, 10)
library(dplyr)
data_numeric <- data_cleaned %>% mutate_at(c("Nino1+2 (SST)", "Nino1+2 (SSTA)", "Nino3 (SST)", "Nino3 (SSTA)",
"Nino34 (SST)", "Nino34 (SSTA)", "Nino4 (SST)", "Nino4 (SSTA)"), as.numeric)
str(data_numeric)
head(data_numeric, 10)
head(data_numeric, row.names = FALSE, 10)
print(data_numeric, row.names = FALSE)
data_numeric, row.names = FALSE
data_numeric
rownames(data_numeric) <- c()
head
head(data_numeric, 10)
data <- read.fwf("./data/getdata_wksst8110.for", widths = c(-1, 9, -5, 4, 4, -5, 4, 4, -5, 4, 4, -5, 4, 4))
colnames(data) <- c("Week", "Nino1+2 (SST)", "Nino1+2 (SSTA)", "Nino3 (SST)", "Nino3 (SSTA)",
"Nino34 (SST)", "Nino34 (SSTA)", "Nino4 (SST)", "Nino4 (SSTA)")
data_cleaned <- data[-c(1:4, 2), ]
row.names(data_cleaned) <- c()
data_numeric <- data_cleaned %>% mutate_at(c("Nino1+2 (SST)", "Nino1+2 (SSTA)", "Nino3 (SST)", "Nino3 (SSTA)",
"Nino34 (SST)", "Nino34 (SSTA)", "Nino4 (SST)", "Nino4 (SSTA)"), as.numeric)
head(data_numeric, 10)
rm(list = ls())
p_unload(all)  # Remove all add-ons
dev.off()  # But only if there IS a plot
cat("\014")  # ctrl+L
setwd("C:/Users/CORMAAL/Desktop/DSEF/DS_Specialisation/03_Getting_And_Cleaning_Data/code")
set.seed(13435)
X <- data.frame("var1" = sample(1:5), "var2" = sample(6:10), "var3" = sample(11:15))
X <- X[sample(1:5), ]; X$var2[c(1, 3)] = NA
X
X[ ,1]
X[, "var1"]
X[1:2, "var2"]
X[(X$var1 <= 3 & X$var3 > 11), ]
X[(X$var1 <= 3 | X$var3 > 15), ]
X[(X$var1 <= 3 | X$var3 > 12), ]
X[(X$var2 > 8), ]
X[which(X$var2 > 8), ]
sort(X$var1)
set.seed(13435)
X <- data.frame("var1" = sample(1:5), "var2" = sample(6:10), "var3" = sample(11:15))
X <- X[sample(1:5), ]; X$var2[c(1, 3)] = NA
X
X[, 1]
X[, "var1"]
X[1:2, "var2"]
X[(X$var1 <= 3 & X$var3 > 11), ]
X[(X$var1 <= 3 | X$var3 > 12), ]
X[which(X$var2 > 8), ]
sort(X$var1)
sort(X$var1, decreasing = TRUE)
sort(X$var2, na.last = TRUE)
sort(X$var1)
# sort(X$var1, decreasing = TRUE)
# sort(X$var2, na.last = TRUE)
X
# sort(X$var1)
# sort(X$var1, decreasing = TRUE)
# sort(X$var2, na.last = TRUE)
set.seed(13435)
X <- data.frame("var1" = sample(1:5), "var2" = sample(6:10), "var3" = sample(11:15))
X <- X[sample(1:5), ]; X$var2[c(1, 3)] = NA
X
rm(list = ls())
set.seed(13435)
X <- data.frame("var1" = sample(1:5), "var2" = sample(6:10), "var3" = sample(11:15))
X <- X[sample(1:5), ]; X$var2[c(1, 3)] = NA
X
X
# sort(X$var1)
# sort(X$var1, decreasing = TRUE)
# sort(X$var2, na.last = TRUE)
X[, 1]
set.seed(13435)
X <- data.frame("var1" = sample(1:5), "var2" = sample(6:10), "var3" = sample(11:15))
X <- X[sample(1:5), ]; X$var2[c(1, 3)] = NA
X
X[, 1]
set.seed(13435)
X <- data.frame("var1" = sample(1:5), "var2" = sample(6:10), "var3" = sample(11:15))
X <- X[sample(1:5), ]; X$var2[c(1, 3)] = NA
X
X[, 1]
X[, "var1"]
X[1:2, "var2"]
X[(X$var1 <= 3 & X$var3 > 11), ]
X[(X$var1 <= 3 | X$var3 > 12), ]
X[which(X$var2 > 8), ]
X
# sort(X$var1)
# sort(X$var1, decreasing = TRUE)
# sort(X$var2, na.last = TRUE)
sort(X$var1)
# sort(X$var1, decreasing = TRUE)
# sort(X$var2, na.last = TRUE)
sort(X$var1)
sort(X$var1, decreasing = TRUE)
# sort(X$var2, na.last = TRUE)
sort(X$var1)
sort(X$var1, decreasing = TRUE)
sort(X$var2, na.last = TRUE)
X[order(X$var1), ]
X[order(X$var1, X$var3), ]
library(plyr)
install.packages("plyr")
library(plyr)
arrange(X, var1)
arrange(X, desc(var1))
X$var4 <- rnorm(5)
X
Y <- cbind(X, rnorm(5))
Y
z <- cbind(rnorm(5), Y)
z
v <- rnorm(5)
A <- cbind(z, v)
A
Z <- rbind(Y, rnorm(5))
Z
rm(list = ls())
setwd("C:/Users/CORMAAL/Desktop/DSEF/DS_Specialisation/03_Getting_And_Cleaning_Data/code")
restData <- read.csv("./data/Restaurants.csv")
restData <- read.csv("./data/Restaurants.csv")
head(restData, 3)
tail(restData, 3)
tail(restData, 3)
head(restData, 3)
summary(restData)
str(restData)
quantile(restData$cncldstn, na.rm = TRUE)
quantile(restData$cncldstn, na.rm = FALSE)
?na.rm
quantile(restData$cncldst, na.rm = TRUE)
quantile(restData$cncldst, na.rm = TRUE, probs = c(0.5, 0.75, 0.9))
table(restData$zipcode, useNA = "ifany")
?table
table(restData$zipcode, useNA = "no")
table(restData$zipcode, useNA = "always")
table(restData$zipcode, useNA = "ifany")
table(restData$cncldst, restData$zipcode)
sum(is.na(restData$cncldst))
any(is.na(restData$cncldst))
all(restData$zipcode > 0)
restData <- read.csv("./data/Restaurants.csv")
summary(restData)
str(restData)
table(restData$zipcode, useNA = "ifany")
table(restData$cncldst, restData$zipcode)
all(restData$zipcode > 0)
colSums(is.na(restData))
all(colSums(restData) == 0)
all(colSums(is.na(restData) == 0)
all(colSums(is.na(restData) == 0))
all(colSums(is.na(restData)) == 0)
View(restData)
table(restData$zipcode %in% c("21212"))
table(restData$zipcode == c("21212"))
table(restData$zipcode %in% c("21212", "21213"))
table(restData$zipcode == "21212")
table(restData$zipcode == 21212)
table(restData$zipcode %in% c(21212, 21213))
restData[restData$zipcode %in% c(21212, 21213), c("name", "zipcode")]
summary(DF)
data("UCBAdmissions")
DF <- as.data.frame(UCBAdmissions)
summary(DF)
xt <- xtabs(Freq ~ Gender + Admit, data=DF)
xt
warpbreaks$replicate <- rep(1:9, len = 54)
xt <- xtabs(breaks ~ ., data = warpbreaks)
xt
ftable(xt)
object.size(fakeData)
fakeData = rnorm(1e5)
fakeData = rnorm(1e5)
object.size(fakeData)
print(object.size(fakeData), units = "Mb")
rm(list = ls())
restData <- read.csv("./data/Restaurants.csv")
restData <- read.csv("./data/Restaurants.csv")
s1 <- seq(1, 10, by = 2)
s1
s2
s2 <- seq(1, 10, length = 3)
s2
s2 <- seq(1, 10, length = 4)
s2
x <- c(1, 3, 8, 25, 100)
seq(along = x)
str(restData)
restData$nearMe <- restData$nghbrhd %in% c("Roland Park", "Homeland")
table(restData$nearMe)
restData$zipGroups <- cut(restData$zipcode, breaks = quantile(restData$zipcode))
table(restData$zipGroups
restData$zipGroups <- cut(restData$zipcode, breaks = quantile(restData$zipcode))
table(restData$zipGroups)
table(restData$zipGroups, restData$zipcode)
library(Hmisc)
restData$zipGroups <- cut2(restData$zipcode, g = 4)
table(restData$zipGroups)
library(Hmisc)
restData$zipGroups <- cut2(restData$zipcode, g = 4)
table(restData$zipGroups)
library(Hmisc)
library(plyr)
restData2 <- mutate(restData, zipGroups = cut2(zipcode, g = 4))
table(restData2$zipGroups)
library(Hmisc)
library(plyr)
restData2 <- mutate(restData, zipGroups = cut2(zipcode, g = 4))
table(restData2$zipGroups)
rm(list = ls())
install.packages("foreign")
library(foreign)
data <- read.fwf("./data/getdata_wksst8110.for", widths = c(-28, 4))
setwd("C:/Users/CORMAAL/Desktop/DSEF/DS_Specialisation/03_Getting_And_Cleaning_Data/code")
data <- read.fwf("./data/getdata_wksst8110.for", widths = c(-28, 4))
str(data)
summary(data)
head(data)
library(dplyr)
data <- read.fwf("./data/getdata_wksst8110.for", widths = c(-1, 9, -5, 4, 4, -5, 4, 4, -5, 4, 4, -5, 4, 4))
colnames(data) <- c("Week", "Nino1+2 (SST)", "Nino1+2 (SSTA)", "Nino3 (SST)", "Nino3 (SSTA)",
"Nino34 (SST)", "Nino34 (SSTA)", "Nino4 (SST)", "Nino4 (SSTA)")
data_cleaned <- data[-c(1:4, 2), ]
row.names(data_cleaned) <- c()
data_numeric <- data_cleaned %>% mutate_at(c("Nino1+2 (SST)", "Nino1+2 (SSTA)", "Nino3 (SST)", "Nino3 (SSTA)",
"Nino34 (SST)", "Nino34 (SSTA)", "Nino4 (SST)", "Nino4 (SSTA)"), as.numeric)
head(data_numeric, 10)
str(data)
head(data_numeric, 10)
str(data_numeric)
